{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel booking\n",
    "\n",
    "### Predicting cancelations\n",
    "It would be nice for the hotels to have a model to predict if a guest will actually come.  \n",
    "This can help a hotel to plan things like personel and food requirements.  \n",
    "Maybe some hotels also use such a model to offer more rooms than they have to make more money... who knows..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup, data inspection and cleanup are hidden for easier reading. Click the Code/Output buttons if you are curious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# common:\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import folium\n",
    "\n",
    "# for ML:\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# set some display options:\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", 36)\n",
    "\n",
    "# load data:\n",
    "file_path = \"hotel_bookings.csv\"\n",
    "full_data = pd.read_csv(file_path)\n",
    "\n",
    "# Replace missing values:\n",
    "# agent: If no agency is given, booking was most likely made without one.\n",
    "# company: If none given, it was most likely private.\n",
    "# rest schould be self-explanatory.\n",
    "nan_replacements = {\"children:\": 0.0,\"country\": \"Unknown\", \"agent\": 0, \"company\": 0}\n",
    "full_data_cln = full_data.fillna(nan_replacements)\n",
    "\n",
    "# \"meal\" contains values \"Undefined\", which is equal to SC.\n",
    "full_data_cln[\"meal\"].replace(\"Undefined\", \"SC\", inplace=True)\n",
    "\n",
    "# Some rows contain entreis with 0 adults, 0 children and 0 babies. \n",
    "# We are dropping these entries with no guests.\n",
    "zero_guests = list(full_data_cln.loc[full_data_cln[\"adults\"]\n",
    "                   + full_data_cln[\"children\"]\n",
    "                   + full_data_cln[\"babies\"]==0].index)\n",
    "full_data_cln.drop(full_data_cln.index[zero_guests], inplace=True)\n",
    "\n",
    "full_data_cln.shape\n",
    "\n",
    "rh = full_data_cln.loc[(full_data_cln[\"hotel\"] == \"Resort Hotel\") & (full_data_cln[\"is_canceled\"] == 0)]\n",
    "ch = full_data_cln.loc[(full_data_cln[\"hotel\"] == \"City Hotel\") & (full_data_cln[\"is_canceled\"] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predict cancelations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which numerical features are most important? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_time                         0.293123\n",
       "total_of_special_requests         0.234658\n",
       "required_car_parking_spaces       0.195498\n",
       "booking_changes                   0.144381\n",
       "previous_cancellations            0.110133\n",
       "is_repeated_guest                 0.084793\n",
       "agent                             0.083114\n",
       "adults                            0.060017\n",
       "previous_bookings_not_canceled    0.057358\n",
       "days_in_waiting_list              0.054186\n",
       "adr                               0.047557\n",
       "babies                            0.032491\n",
       "stays_in_week_nights              0.024765\n",
       "company                           0.020642\n",
       "arrival_date_year                 0.016660\n",
       "arrival_date_week_number          0.008148\n",
       "arrival_date_day_of_month         0.006130\n",
       "children                          0.005048\n",
       "stays_in_weekend_nights           0.001791\n",
       "Name: is_canceled, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancel_corr = full_data.corr(numeric_only = True)[\"is_canceled\"]\n",
    "cancel_corr.abs().sort_values(ascending=False)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_time                         0.293123\n",
       "total_of_special_requests         0.234658\n",
       "required_car_parking_spaces       0.195498\n",
       "booking_changes                   0.144381\n",
       "previous_cancellations            0.110133\n",
       "is_repeated_guest                 0.084793\n",
       "agent                             0.083114\n",
       "adults                            0.060017\n",
       "previous_bookings_not_canceled    0.057358\n",
       "days_in_waiting_list              0.054186\n",
       "adr                               0.047557\n",
       "babies                            0.032491\n",
       "stays_in_week_nights              0.024765\n",
       "company                           0.020642\n",
       "arrival_date_year                 0.016660\n",
       "arrival_date_week_number          0.008148\n",
       "arrival_date_day_of_month         0.006130\n",
       "children                          0.005048\n",
       "stays_in_weekend_nights           0.001791\n",
       "Name: is_canceled, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancel_corr = full_data.corr(numeric_only = True)[\"is_canceled\"]\n",
    "cancel_corr.abs().sort_values(ascending=False)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list it is apparent that lead_time, total_of_special_requests, required_car_parking_spaces, booking_changes and previous_cancellations are the 5 most important numerical features.  \n",
    "However, to predict wheater or not a booking will be canceled, the number of booking changes is a possible source of leakage, because this information can change over time.  \n",
    "I will also not include days_in_waiting_list and arrival_date_year.  \n",
    "  \n",
    "The most important feature to exclude is the \"reservation_status\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_canceled  reservation_status\n",
       "0            Check-Out             75166\n",
       "1            Canceled              43017\n",
       "             No-Show                1207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.groupby(\"is_canceled\")[\"reservation_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing different base models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually choose columns to include\n",
    "# some columns are excluded to make the model more general and to prevent leakage\n",
    "# (arrival_date_year, assigned_room_type, booking_changes, reservation_status, country,\n",
    "# days_in_waiting_list)\n",
    "# including the country would increase accuracy, but it may also make the model less general\n",
    "\n",
    "num_features = [\"lead_time\",\"arrival_date_week_number\",\"arrival_date_day_of_month\",\n",
    "                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n",
    "                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n",
    "                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n",
    "                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n",
    "\n",
    "cat_features = [\"hotel\",\"arrival_date_month\",\"meal\",\"market_segment\",\n",
    "                \"distribution_channel\",\"reserved_room_type\",\"deposit_type\",\"customer_type\"]\n",
    "\n",
    "# Separate features and predicted value\n",
    "features = num_features + cat_features\n",
    "X = full_data.drop([\"is_canceled\"], axis=1)[features]\n",
    "y = full_data[\"is_canceled\"]\n",
    "\n",
    "# preprocess numerical feats:\n",
    "# for most num cols, except the dates, 0 is the most logical choice as fill value\n",
    "# and here no dates are missing.\n",
    "num_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "# Preprocessing for categorical features:\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical features:\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_features),\n",
    "                                               (\"cat\", cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT_model cross validation accuarcy score: 0.8246 +/- 0.0016 (std) min: 0.8221, max: 0.8263\n",
      "RF_model cross validation accuarcy score: 0.8664 +/- 0.0012 (std) min: 0.8646, max: 0.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_model cross validation accuarcy score: 0.7937 +/- 0.0011 (std) min: 0.7921, max: 0.7951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB_model cross validation accuarcy score: 0.8456 +/- 0.0004 (std) min: 0.8451, max: 0.8461\n"
     ]
    }
   ],
   "source": [
    "# define models to test:\n",
    "base_models = [(\"DT_model\", DecisionTreeClassifier(random_state=42)),\n",
    "               (\"RF_model\", RandomForestClassifier(random_state=42,n_jobs=-1)),\n",
    "               (\"LR_model\", LogisticRegression(random_state=42,n_jobs=-1)),\n",
    "               (\"XGB_model\", XGBClassifier(random_state=42, n_jobs=-1))]\n",
    "\n",
    "# split data into 'kfolds' parts for cross validation,\n",
    "# use shuffle to ensure random distribution of data:\n",
    "kfolds = 4 # 4 = 75% train, 25% validation\n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "\n",
    "# Preprocessing, fitting, making predictions and scoring for every model:\n",
    "for name, model in base_models:\n",
    "    # pack preprocessing of data and the model in a pipeline:\n",
    "    model_steps = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)])\n",
    "    \n",
    "    # get cross validation score for each model:\n",
    "    cv_results = cross_val_score(model_steps, \n",
    "                                 X, y, \n",
    "                                 cv=split,\n",
    "                                 scoring=\"accuracy\",\n",
    "                                 n_jobs=-1)\n",
    "    # output:\n",
    "    min_score = round(min(cv_results), 4)\n",
    "    max_score = round(max(cv_results), 4)\n",
    "    mean_score = round(np.mean(cv_results), 4)\n",
    "    std_dev = round(np.std(cv_results), 4)\n",
    "    print(f\"{name} cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")\n",
    "    \n",
    "    #pipeline.fit(X_train, y_train)\n",
    "    #preds = pipeline.predict(X_valid)\n",
    "    #score = accuracy_score(y_valid, preds)\n",
    "    #print(f\"{name} accuracy_score: {round(score, 4)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForst model performs best.  \n",
    "I also did some hyperparameter optimization, but the accuracy increase is minimal:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced RF model cross validation accuarcy score: 0.8681 +/- 0.0006 (std) min: 0.8673, max: 0.869\n"
     ]
    }
   ],
   "source": [
    "# Enhanced RF model with the best parameters I found:\n",
    "rf_model_enh = RandomForestClassifier(n_estimators=160,\n",
    "                               max_features=0.4,\n",
    "                               min_samples_split=2,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=0)\n",
    "\n",
    "split = KFold(n_splits=kfolds, shuffle=True, random_state=42)\n",
    "model_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', rf_model_enh)])\n",
    "cv_results = cross_val_score(model_pipe, \n",
    "                                 X, y, \n",
    "                                 cv=split,\n",
    "                                 scoring=\"accuracy\",\n",
    "                                 n_jobs=-1)\n",
    "# output:\n",
    "min_score = round(min(cv_results), 4)\n",
    "max_score = round(max(cv_results), 4)\n",
    "mean_score = round(np.mean(cv_results), 4)\n",
    "std_dev = round(np.std(cv_results), 4)\n",
    "print(f\"Enhanced RF model cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
